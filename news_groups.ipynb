{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e1f6ae-75c0-4032-a8fc-9bc5669e3b49",
   "metadata": {},
   "source": [
    "# Training a binary classifier \n",
    "\n",
    "Going to train a binary classifier on a real world dataset of __[20 news groups](http://https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset)__ from the scikit-learn datasets. The result of \n",
    "the fetch is a dataframe with the news group posts. The remove parameter removes the post headers, footers, and quotations of other posts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4bf5bc-8ace-4851-a8b3-5e7facd15a02",
   "metadata": {},
   "source": [
    "***\n",
    "## Data Prep\n",
    "\n",
    "Read the data with outcomes: <tt><b>X</b><sub><i>n,2</i></sub></tt> Note that news_groups is n,3 because of the redundant binary ratings column. \n",
    "\n",
    "Vector <b>y</b><sub>n</sub> is the column that contains binary outcomes. These are converted to ones and zeros.\n",
    "\n",
    "Data without outcomes: <tt><b>x</b><sub><i>n</i></sub> =  <b>X</b><sub><i>n,2</i></sub> - <b>y</b><sub>n</sub>  </tt>\n",
    "\n",
    "<tt><b>x_train</b><sub><i>p</i></sub>, <b>x_test</b><sub><i>q</i></sub>, <b>y_train</b><sub><i>p</i></sub>, <b>y_test</b><sub><i>q</i></sub> = train_test_split(<b>x</b><sub><i>n</i></sub>, <b>y</b><sub>n</sub> )  where n = p + q\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer().fit(<b>x_train</b><sub><i>p</i></sub>)   \n",
    "\n",
    "<b>X_train_vectorized</b><sub><i>p,u</i></sub> = vect.transform(<b>x_train</b><sub><i>p</i></sub>)  u: indeterminate\n",
    "\n",
    "<b>X_test_vectorized</b><sub><i>q,*u</i></sub> = vect.transform(<b>x_test</b><sub><i>q</i></sub>)  u: indeterminate\n",
    "</tt>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291132ca-d3ff-470b-924c-1da5cbfefd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  targets\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...       10\n",
       "1  My brother is in the market for a high-perform...        3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sklearn\n",
    "import sklearn.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "bunch = datasets.fetch_20newsgroups(subset='all',\n",
    "                                   remove=('headers',\n",
    "                                          'footers',\n",
    "                                          'quotes'))\n",
    "\n",
    "news_groups = {'data':bunch['data'],\n",
    "              'targets':bunch['target'],}\n",
    "\n",
    "news_groups = pd.DataFrame(news_groups)\n",
    "news_groups.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3335ce9-bbc7-471a-94dd-35639730b84e",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The news groups data is a multi-class classification problem. We turn this into a binary classification by \n",
    "set of related news groups to 1 and the others to 0.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "307ef660-6015-4fa0-ab36-a87ec65adb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>targets</th>\n",
       "      <th>binary_tgts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nBack in high school I worked as a lab assi...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nAE is in Dallas...try 214/241-6060 or 214/...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n[stuff deleted]\\n\\nOk, here's the solution t...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n\\nYeah, it's the second one.  And I believ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nIf a Christian means someone who believes in...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the blood of the lamb.\\n\\nThis will be a hard ...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&gt;say they have a \"history of untrustworthy be...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>930418\\n\\nDo what thou wilt shall be the whole...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How about Kirlian imaging ? I believe the FAQ...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\n\\n\\tThere is no notion of heliocentric, or e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In the following report: _Turkey Eyes Regional...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Many thanks to those who replied to my appeal ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.........\\nI, some years ago, almost became a ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\nThe Supreme Court seems to disagree with you...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\ned&gt;1.  All of us that argue about gyroscopes...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 data  targets  binary_tgts\n",
       "0   \\n\\nI am sure some bashers of Pens fans are pr...       10            0\n",
       "1   My brother is in the market for a high-perform...        3            0\n",
       "2   \\n\\n\\n\\n\\tFinally you said what you dream abou...       17            0\n",
       "3   \\nThink!\\n\\nIt's the SCSI card doing the DMA t...        3            0\n",
       "4   1)    I have an old Jasmine drive which I cann...        4            0\n",
       "5   \\n\\nBack in high school I worked as a lab assi...       12            0\n",
       "6   \\n\\nAE is in Dallas...try 214/241-6060 or 214/...        4            0\n",
       "7   \\n[stuff deleted]\\n\\nOk, here's the solution t...       10            0\n",
       "8   \\n\\n\\nYeah, it's the second one.  And I believ...       10            0\n",
       "9   \\nIf a Christian means someone who believes in...       19            0\n",
       "10  the blood of the lamb.\\n\\nThis will be a hard ...       19            0\n",
       "11   >say they have a \"history of untrustworthy be...       11            0\n",
       "12  930418\\n\\nDo what thou wilt shall be the whole...       19            0\n",
       "13   How about Kirlian imaging ? I believe the FAQ...       13            0\n",
       "14  \\n\\n\\tThere is no notion of heliocentric, or e...        0            1\n",
       "15  In the following report: _Turkey Eyes Regional...       17            0\n",
       "16  Many thanks to those who replied to my appeal ...       12            0\n",
       "17  .........\\nI, some years ago, almost became a ...       12            0\n",
       "18  \\nThe Supreme Court seems to disagree with you...       11            0\n",
       "19  \\ned>1.  All of us that argue about gyroscopes...        8            0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Drop missing values, if there are any.\n",
    "news_groups.dropna(inplace=True)\n",
    "\n",
    "def set_binary_targets(data_series):\n",
    "    #data_series = np.where((((data_series < 6) & data_series != 0)), 1, 0)\n",
    "    data_series = np.where(data_series == 0, 1, 0)\n",
    "    return data_series\n",
    "\n",
    "# There are 20 news groups, making for a \n",
    "news_groups['binary_tgts'] = set_binary_targets(news_groups['targets'])\n",
    "\n",
    "news_groups.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0df7fc1-b582-4b25-8919-89585709ae6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comp.windows.x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                target names\n",
       "0                alt.atheism\n",
       "1              comp.graphics\n",
       "2    comp.os.ms-windows.misc\n",
       "3   comp.sys.ibm.pc.hardware\n",
       "4      comp.sys.mac.hardware\n",
       "5             comp.windows.x\n",
       "6               misc.forsale\n",
       "7                  rec.autos\n",
       "8            rec.motorcycles\n",
       "9         rec.sport.baseball\n",
       "10          rec.sport.hockey\n",
       "11                 sci.crypt\n",
       "12           sci.electronics\n",
       "13                   sci.med\n",
       "14                 sci.space\n",
       "15    soc.religion.christian\n",
       "16        talk.politics.guns\n",
       "17     talk.politics.mideast\n",
       "18        talk.politics.misc\n",
       "19        talk.religion.misc"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgts = pd.DataFrame(bunch['target_names'], columns=['target names'])\n",
    "tgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13879e9f-7738-4002-81cc-b5f1ae8698f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "targets\n",
       "10    999\n",
       "15    997\n",
       "8     996\n",
       "9     994\n",
       "11    991\n",
       "7     990\n",
       "13    990\n",
       "5     988\n",
       "14    987\n",
       "2     985\n",
       "12    984\n",
       "3     982\n",
       "6     975\n",
       "1     973\n",
       "4     963\n",
       "17    940\n",
       "16    910\n",
       "0     799\n",
       "18    775\n",
       "19    628\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our target set is a small percentage of the overall data.\n",
    "# There will not be much to train the classifier\n",
    "\n",
    "news_groups['targets'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "783dffc1-7e23-4789-8707-5e88745ecd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>targets</th>\n",
       "      <th>binary_tgts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18846.000000</td>\n",
       "      <td>18846.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.293166</td>\n",
       "      <td>0.042396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.562798</td>\n",
       "      <td>0.201497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            targets   binary_tgts\n",
       "count  18846.000000  18846.000000\n",
       "mean       9.293166      0.042396\n",
       "std        5.562798      0.201497\n",
       "min        0.000000      0.000000\n",
       "25%        5.000000      0.000000\n",
       "50%        9.000000      0.000000\n",
       "75%       14.000000      0.000000\n",
       "max       19.000000      1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only 5.3% of the data in 'rec.autos'. \n",
    "# Only 4.2% of the data is in 'alt.atheism.'\n",
    "news_groups.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e764f-6862-4ca8-8c2d-a84aa4c38d0b",
   "metadata": {},
   "source": [
    "*** \n",
    "Create the training and the test data.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46b2a332-9118-4156-bde7-0689ff4fa892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "news_groups shape:  (18846, 3)\n",
      "\n",
      "X_train shape:  (14134,) \ty_train shape:  (14134,)\n",
      "X_test shape:  (4712,) \t\ty_test shape:  (4712,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(news_groups['data'], \n",
    "                                                    news_groups['binary_tgts'], \n",
    "                                                    random_state=0)\n",
    "print('\\nnews_groups shape: ', news_groups.shape)\n",
    "print('\\nX_train shape: ', X_train.shape, '\\ty_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape, '\\t\\ty_test shape: ', y_test.shape,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe784a40-a52f-4355-957a-0599dab88f50",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "\n",
    "The scikit learn machine learning algorithms\n",
    "cannot process words, so vectorization produces a unique numerical representation for all the words in all the posts in the input data. In text processing, the union of the news group posts is called the text <b>corpus</b> and each post is a <b>document</b>. The <b>__[CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)__,</b> ignores text structure and only counts occurances of words to do its vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6fce86c-2abe-4580-9552-2e19feeb7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#\n",
    "# Fit the CountVectorizer to the training data\n",
    "vect_VC = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20a4ba42-dfaf-49b6-9b92-1b360fa1ae04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104069"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of words in the corpus.\n",
    "len(vect_VC.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f032ca4-cef9-4f8c-ae6d-01e9aa16d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '164690', '3049', '5gppfjsq', '8574', 'a1c', 'animals',\n",
       "       'ballyhoo', 'brouillette', 'christain', 'correlate', 'demonstate',\n",
       "       'dustribute', 'exaclty', 'forsook', 'graphi', 'holger', 'inguianl',\n",
       "       'justifiably', 'leans', 'macrocosm', 'minorit', 'napoleonic',\n",
       "       'olcay', 'peripherals', 'proj', 'reamins', 'roussor', 'shawon',\n",
       "       'ssa', 'taller', 'truth', 'v6eh', 'wheat', 'xvt'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_VC.get_feature_names_out()[::3000]   # look at every 3000th feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cca870d-5d5c-4009-99e0-0654c59d8736",
   "metadata": {},
   "source": [
    "***\n",
    "We have over 100,000 features (unique words in the corpus) and only 14,000 samples (individual documents in X_train). We can expect that the classifer will not perform well.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6be0e-f121-4f34-8304-5d073ebdc8fd",
   "metadata": {},
   "source": [
    "***\n",
    "Transform the documents in the training data to a document-term matrix.\n",
    "\n",
    "* Each row corresponds to a document: 14134. \n",
    "* Each column corresponds to a word in the vocabulary or corpus: 104,069.\n",
    "* The entries represent the number of times the word appears in each document: 1,339,229.\n",
    "\n",
    "Since most words do not appear in most documents, the array is sparce with many zero enties.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21c2b096-cb4b-4e88-aad1-5ff662212fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14134x104069 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1339229 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized_VC = vect_VC.transform(X_train)\n",
    "\n",
    "X_train_vectorized_VC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f9ac3-7bf0-4e8f-bc7d-08fcc1ed3276",
   "metadata": {},
   "source": [
    "***\n",
    "The LogisticRegression model is good with high dimensional, sparce data.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d0359a9-6d21-4694-a966-55d42f9200b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_VC.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7f9e7ad-fd48-471c-b631-9316a67733a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# works well for high dimentional sparce data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "model_VC = LogisticRegression(max_iter=1000)\n",
    "model_VC.fit(X_train_vectorized_VC, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c92a22-9cc2-4f14-b4d0-508d0e9fcab9",
   "metadata": {},
   "source": [
    "***\n",
    "Now use the model to predict the outcomes for X_test. \n",
    "\n",
    "We have the predicted outcomes for X_test, but we also have the actual outcomes, y_test. So now we can compute a measure of the performance of the model, the __[area under the curve(AUC)](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)__.\n",
    "\n",
    "An AUC value of 0.5 is the equivalent of random guessing. This is because we have so many features and not enough samples.\n",
    "\n",
    "There are methods to improve the peformance.\n",
    "\n",
    "test_data_and_results is a dataframe where we aggregate data and results for comparison and error checking purposes.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cec3b43-c5e9-4d41-9478-78d11900b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6800424272270235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>predictions_VC</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14736</th>\n",
       "      <td>Uh... slight clarification:  That should be ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       x  predictions_VC  \\\n",
       "14736    Uh... slight clarification:  That should be ...               0   \n",
       "\n",
       "       y_test  \n",
       "14736       0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Predict the transformed test documents\n",
    "\n",
    "predictions_VC = model_VC.predict(vect_VC.transform(X_test))\n",
    "\n",
    "test_data_and_results = pd.DataFrame({'x':X_test, 'predictions_VC': predictions_VC}) \n",
    "test_data_and_results['y_test'] = y_test\n",
    "\n",
    "# any words that appear in X_test that are not in X_train are ignored.\n",
    "print('AUC: ', roc_auc_score(y_test, predictions_VC))\n",
    "test_data_and_results.describe()\n",
    "test_data_and_results.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42e0ef45-b7aa-4542-826b-39435a35ea8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27014 99807 40316 68747 99376 75317 82925 39995 25174 66806]\n",
      "Smallest Coefs:\n",
      "['christians' 'wondering' 'fbi' 'off' 'windows' 'provide' 'scripture'\n",
      " 'fake' 'called' 'next']\n",
      "\n",
      "Largest Coefs: \n",
      "['bobby' 'motto' 'atheism' 'atheists' 'conner' 'atheist' 'keith' 'loans'\n",
      " 'cruel' 'define']\n"
     ]
    }
   ],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = vect_VC.get_feature_names_out()\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model_VC.coef_[0].argsort()\n",
    "\n",
    "print(sorted_coef_index[0:10])\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c873515-8b54-4920-b927-75e673e99fc9",
   "metadata": {},
   "source": [
    "***\n",
    "## TfidfVectorizer: term-frequency times inverse document-frequency\n",
    "\n",
    "Fit the __[TfidfVectorizer](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) to the training data specifiying a minimum document frequency of 5\n",
    "\n",
    "Weight terms based on how important they are to a document. High weight is given to terms that appear often in a document but not in the corpus.\n",
    "\n",
    "min_df: the minimum number of documents in which a word has to appear\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3b2d963-c935-44f6-9c0e-637130eb3085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5460086477944878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect_tfid = TfidfVectorizer().fit(X_train)\n",
    "\n",
    "X_train_vectorized_tfid = vect_tfid.transform(X_train)\n",
    "\n",
    "# works well for high dimentional sparce data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_tfid = LogisticRegression(max_iter=1000)\n",
    "model_tfid.fit(X_train_vectorized_tfid, y_train)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# predictions = model.predict_proba(vect.transform(X_test))\n",
    "predictions_tfid = model_tfid.predict(vect_tfid.transform(X_test))\n",
    "#binary_predictions_tfid = set_binary_targets(predictions_tfid)\n",
    "print('AUC: ', roc_auc_score(y_test, predictions_tfid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bba88b4e-144d-4fc3-a280-33849a92fa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104069"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect_tfid = TfidfVectorizer().fit(X_train)\n",
    "len(vect_tfid.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ded46e3b-fd36-4765-b753-1ab5d777bf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '164690', '3049', '5gppfjsq', '8574', 'a1c', 'animals',\n",
       "       'ballyhoo', 'brouillette', 'christain', 'correlate', 'demonstate',\n",
       "       'dustribute', 'exaclty', 'forsook', 'graphi', 'holger', 'inguianl',\n",
       "       'justifiably', 'leans', 'macrocosm', 'minorit', 'napoleonic',\n",
       "       'olcay', 'peripherals', 'proj', 'reamins', 'roussor', 'shawon',\n",
       "       'ssa', 'taller', 'truth', 'v6eh', 'wheat', 'xvt'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_tfid.get_feature_names_out()[::3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b99b589-ac37-4b1b-8066-f0c71f0d51d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14134x104069 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1339229 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_tfid = vect_tfid.transform(X_train)\n",
    "X_train_vectorized_tfid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "693e0cb9-487d-44cf-ba4e-519a3d4a3cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# works well for high dimentional sparce data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_tfid = LogisticRegression(max_iter=1000)\n",
    "model_tfid.fit(X_train_vectorized_tfid, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd8f58b6-d4bb-40e3-97c6-a4d1c1065d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5460086477944878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# predictions = model.predict_proba(vect.transform(X_test))\n",
    "predictions_tfid = model_tfid.predict(vect_tfid.transform(X_test))\n",
    "#binary_predictions_tfid = set_binary_targets(predictions_tfid)\n",
    "test_data_and_results['predictions_tfid'] = predictions_tfid\n",
    "\n",
    "#binary_predictions_tfid = set_binary_targets(predictions_tfid)\n",
    "print('AUC: ', roc_auc_score(y_test, predictions_tfid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ca8d004-e047-4778-ae2d-0010603ffe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      "['yf9f9f9f9f9f9f9f9f9f3t' 'kljn' 'newwj' 'wz4'\n",
      " '3v9f9f9f9f9f9f9f9f9f9f9f9f9' 'ewwhj' 'ewwj' '3v9f9f9f9f9f9f9f0' 'pnewwj'\n",
      " 'nrizwz4']\n",
      "\n",
      "Largest tfidf: \n",
      "['narrative' 'ditto' 'hello' 'anaheim' 'david' 'each' 'why' 'dir'\n",
      " 'consistently' 'art']\n"
     ]
    }
   ],
   "source": [
    "feature_names_tfid = np.array(vect_tfid.get_feature_names_out())\n",
    "\n",
    "sorted_index_tfid = X_train_vectorized_tfid.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest tfidf:\\n{}\\n'.format(feature_names_tfid[sorted_index_tfid[:10]]))\n",
    "print('Largest tfidf: \\n{}'.format(feature_names_tfid[sorted_index_tfid[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "225b6502-0b7a-480a-97c9-b2afeb7def30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['the' 'with' 'on' 'get' 'windows' 'use' 'will' 'for' 'off' 'israel']\n",
      "\n",
      "Largest Coefs: \n",
      "['atheism' 'religion' 'atheists' 'islam' 'atheist' 'bobby' 'islamic'\n",
      " 'morality' 'kent' 'motto' 'god' 'belief' 'is' 'rushdie' 'that' 'cobb'\n",
      " 'what' 'cruel' 'moral' 'an' 'theists']\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model_tfid.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names_tfid[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names_tfid[sorted_coef_index[:-22:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf4d488f-ed09-4efd-9c35-aa05fc7c834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76480"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect_ngram = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect_ngram.transform(X_train)\n",
    "\n",
    "len(vect_ngram.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57bfcda1-cff4-4653-ad9e-6920eaf86f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.3392478908148301\n"
     ]
    }
   ],
   "source": [
    "model_ngram = LogisticRegression(max_iter=1000)\n",
    "model_ngram.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions_ngram = model_ngram.predict(vect_ngram.transform(X_test))\n",
    "binary_predictions_ngram = set_binary_targets(predictions_ngram)\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, binary_predictions_ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ae20c56-2658-4af4-89ff-21e0e73fca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['they were' 'windows' 'off' 'christians' 'wondering' 'you can' 'hi'\n",
      " 'phone' 'called' 'let']\n",
      "\n",
      "Largest Coefs: \n",
      "['conner' 'atheists' 'atheism' 'keith' 'atheist' 'bobby' 'religion'\n",
      " 'claim that' 'answered' 'gregg']\n"
     ]
    }
   ],
   "source": [
    "feature_names_ngram = np.array(vect_ngram.get_feature_names_out())\n",
    "\n",
    "sorted_coef_index_ngram = model_ngram.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names_ngram[sorted_coef_index_ngram[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names_ngram[sorted_coef_index_ngram[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd89feec-5475-4b7e-9950-938b3339efb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ef26df-a851-4483-9326-5cd2454f5530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
